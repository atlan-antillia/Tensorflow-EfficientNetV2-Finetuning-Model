<h2>EfficientNetV2-Oral-Cancer</h2>
 This is an experimental EfficientNetV2 Oral-Cancer Classification project based on <b>efficientnetv2</b> 
 in <a href="https://github.com/google/automl">Brain AutoML</a>.
 <br>
Please see also our first experiment <a href="https://github.com/atlan-antillia/EfficientNet-Oral-Cancer">EfficientNet-Oral-Cancer</a><br>

<h3>1. Dataset Citation</h3>
The original Oral-Cancer dataset has been taken from the following website:<br>
<a href="https://github.com/naveen3124/Oral-Cancer-Deep-Learning-">Oral-Cancer-Deep-Learning-
</a>

<h3>2. Download dataset</h3>
If you would like to train Oral-Cancer Model by yourself,
please download the dataset from the google drive 
<a href="https://drive.google.com/file/d/196wZkndaLN2-c8PGXr_LIPf97pHvua_L/view?usp=sharing">Oral_Cancer_Images.zip</a>
<br>
It contains the following test and train datasets.<br>
<pre>
Oral_Cancer_Images
├─test
│  ├─Class0
│  └─Class1
└─train
    ├─Class0
    └─Class1
</pre>
The number of images in this dataset is the following:<br>
<img src="./_Oral_Cancer_Images_.png" width="740" height="auto"><br>
<br>
<br>
Oral_Cancer_Images/train/Class0:<br>
<img src="./asset/Oral_Cancer_train_Class0.png" width="840" height="auto">
<br>
<br>
Oral_Cancer_Images/train/Class1:<br>
<img src="./asset/Oral_Cancer_train_Class1.png" width="840" height="auto">
<br>
<br>

<h3>
3. Train
</h3>
<h3>
3.1 Training script
</h3>
Please run the following bat file to train our Oral-Cancer Classification Model by using
<b>Oral-Cancer_Images/train</b>.
<pre>
./1_train.bat
</pre>
<pre>
rem 1_train.bat
rem 2024/01/01
python ../../../efficientnetv2/EfficientNetV2ModelTrainer.py ^
  --model_dir=./models ^
  --eval_dir=./eval ^
  --model_name=efficientnetv2-m  ^
  --data_generator_config=./data_generator.config ^
  --ckpt_dir=../../../efficientnetv2/efficientnetv2-m/model ^
  --optimizer=rmsprop ^
  --image_size=384 ^
  --eval_image_size=480 ^
  --data_dir=./Oral_Cancer_Images/train ^
  --data_augmentation=True ^
  --valid_data_augmentation=False ^
  --fine_tuning=True ^
  --monitor=val_loss ^
  --learning_rate=0.0001 ^
  --trainable_layers_ratio=0.4 ^
  --dropout_rate=0.2 ^
  --num_epochs=50 ^
  --batch_size=4 ^
  --patience=10 ^
  --debug=True  
</pre>
, where data_generator.config is the following:<br>
<pre>
; data_generation.config
; 2024/01/10
[training]
validation_split   = 0.2
featurewise_center = True
samplewise_center  = False
featurewise_std_normalization=True
samplewise_std_normalization =False
zca_whitening                =False
rotation_range     = 90
horizontal_flip    = True
vertical_flip      = True 
width_shift_range  = 0.2
height_shift_range = 0.2
shear_range        = 0.1
zoom_range         = [0.2, 3.0]
data_format        = "channels_last"
</pre>

<h3>
3.2 Training result
</h3>

This will generate a <b>best_model.h5</b> in the models folder specified by --model_dir parameter.<br>
Furthermore, it will generate a <a href="./eval/train_accuracies.csv">train_accuracies.csv</a>
and <a href="./eval/train_losses.csv">train_losses</a> files
<br>
Training console output:<br>
<img src="./asset/Oral_Cancer_train_console_at_epoch_39_0106.png" width="740" height="auto"><br>
<br>
Train_accuracies:<br>
<img src="./eval/train_accuracies.png" width="640" height="auto"><br>

<br>
Train_losses:<br>
<img src="./eval/train_losses.png" width="640" height="auto"><br>

<br>
<h3>
4. Inference
</h3>
<h3>
4.1 Inference script
</h3>
Please run the following bat file to infer the breast cancer in test images by the model generated by the above train command.<br>
<pre>
./2_inference.bat
</pre>
<pre>
rem 2_inference.bat
rem 2024/01/01
python ../../../efficientnetv2/EfficientNetV2Inferencer.py ^
  --model_name=efficientnetv2-m  ^
  --model_dir=./models ^
  --fine_tuning=True ^
  --trainable_layers_ratio=0.4 ^
  --dropout_rate=0.2 ^
  --image_path=./test/*.jpg ^
  --eval_image_size=480 ^
  --label_map=./label_map.txt ^
  --mixed_precision=True ^
  --infer_dir=./inference ^
  --debug=False 
</pre>
<br>
label_map.txt:
<pre>
Class0
Class1
</pre>
<br>
<h3>
4.2 Sample test images
</h3>

Sample test images generated by <a href="./create_test_dataset.py">create_test_dataset.py</a> 
from <a href="./Oral-Cancer_Images/test">Oral-Cancer_Images/test</a>.
<br>
<img src="./asset/Oral_Cancer_test.png" width="840" height="auto"><br>

<h3>
4.3 Inference result
</h3>
This inference command will generate <a href="./inference/inference.csv">inference.csv</a>.
<br>
<br>
Inference console output:<br>
<img src="./asset/Oral_Cancer_infer_console_at_epoch_39_0106.png" width="740" height="auto"><br>
<br>

Inference result (inference.csv):<br>
<img src="./asset/Oral_Cancer_inference_csv_at_epoch_39_0106.png" width="740" height="auto"><br>
<br>
<h2>
<5. Evaluation
</h2>
<h3>
5.1 Evaluation script
</h3>
Please run the following bat file to evaluate <a href="./Oral_Cancer_Images/test">
Oral_Cancer_Images/test</a> by the trained model.<br>
<pre>
./3_evaluate.bat
</pre>
<pre>
rem 3_evaluate.bat
rem 2024/01/01
python ../../../efficientnetv2/EfficientNetV2Evaluator.py ^
  --model_name=efficientnetv2-m  ^
  --model_dir=./models ^
  --data_dir=./Oral_Cancer_Images/test ^
  --evaluation_dir=./evaluation ^
  --fine_tuning=True ^
  --trainable_layers_ratio=0.4 ^
  --dropout_rate=0.2 ^
  --eval_image_size=480 ^
  --mixed_precision=True ^
  --debug=False 
</pre>
<br>

<h3>
5.2 Evaluation result
</h3>

This evaluation command will generate <a href="./evaluation/classification_report.csv">a classification_report.csv</a>
 and <a href="./evaluation/confusion_matrix.png">a confusion_matrix</a>.
<br>
<br>
Evaluation console output:<br>
<img src="./asset/Oral_Cancer_evaluate_console_at_epoch_39_0106.png" width="740" height="auto"><br>
<br>

<br>
Classification report:<br>
<img src="./asset/Oral_Cancer_classificaiton_report_at_epoch_39_0106.png" width="740" height="auto"><br>
<br>
Confusion matrix:<br>
<img src="./evaluation/confusion_matrix.png" width="740" height="auto"><br>


<br>
<h3>
References
</h3>
<b>1. Oral-Cancer-Deep-Learning-</b><br>
<pre>
https://github.com/naveen3124/Oral-Cancer-Deep-Learning-#oral-cancer-deep-learning-
</pre>

